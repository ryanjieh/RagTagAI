{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28ebc409",
   "metadata": {},
   "source": [
    "1. importing data\n",
    "- image as jpeg\n",
    "- text as txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "178202c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1960, 1433, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the image (BGR format by default in OpenCV)\n",
    "img_array = cv2.imread(\"./sample reddit post/picture.jpeg\")\n",
    "\n",
    "# Convert BGR to RGB (if needed)\n",
    "img_array_rgb = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "print(img_array.shape)  # (height, width, channels)\n",
    "\n",
    "#image into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52800d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text input \n",
    "with open('./sample reddit post/comments.txt', 'r') as commentsfile:\n",
    "    comments = commentsfile.read()  # Entire content as a single string\n",
    "#print(comments)\n",
    "with open('./sample reddit post/post.txt', 'r') as postfile:\n",
    "    post = postfile.read()  # Entire content as a single string\n",
    "#print(post)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a14ccd",
   "metadata": {},
   "source": [
    "2. preprocessing of texts and image\n",
    "Text \n",
    "- Sentiment analysis on text (out of box specialised sentiment analysis model)\n",
    "- summary/suggestions on the text (for now, out of box model)\n",
    "Image\n",
    "- ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d389907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'Very Negative', 'score': 0.5712113976478577}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntruncated_comments = \"this is fantastic!\"\\nresult = pipe(truncated_comments)\\nprint(result)\\n\\ntruncated_comments = \"worst fit ive seen in my life\"\\nresult = pipe(truncated_comments)\\nprint(result)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#attempt to do sentiment analysis on the comments\n",
    "#used a huggingface sentiment analysis multilingual transformer. \n",
    "#Selected this one because of fine-grained classification of sentiments\n",
    "#is multilingual distilbert fine-tuned into a sentiment analysis model\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the classification pipeline with the specified model\n",
    "pipe = pipeline(model=\"tabularisai/multilingual-sentiment-analysis\")\n",
    "\n",
    "#unable to run as the amount of text in comments thread (this isnt even the whole comments thread) is too big\n",
    "#needs to be embedded into 512 tokens\n",
    "truncated_comments = comments[:1500]\n",
    "result = pipe(truncated_comments)\n",
    "print(result)\n",
    "\n",
    "'''\n",
    "truncated_comments = \"this is fantastic!\"\n",
    "result = pipe(truncated_comments)\n",
    "print(result)\n",
    "\n",
    "truncated_comments = \"worst fit ive seen in my life\"\n",
    "result = pipe(truncated_comments)\n",
    "print(result)\n",
    "'''\n",
    "#future work: get reddit comments in json and weight each individual comment. finally, we can aggregate an approval rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7b2a2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 1639, 80% upvoted Comments: 1667 - TheOriginalChar\n"
     ]
    }
   ],
   "source": [
    "#attempt to summarise text\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google-t5/t5-small\")\n",
    "\n",
    "inputs = tokenizer(\n",
    "    \"this is a list of comments from a reddit conversation. Please give a list of suggestions: \" + truncated_comments, return_tensors=\"pt\").input_ids  # Batch size 1\n",
    "outputs = model.generate(inputs)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "#oh no it generates gibberish. definitely in need of fine tuning \n",
    "#https://docs.google.com/document/d/1zjGPga0c4SOzu2_3Lsqd0W-ER-or15gHazkYsL2vvRs/edit?usp=sharing for ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1947a26b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
